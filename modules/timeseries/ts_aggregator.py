#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CoreFlow TS Aggregator v2.5 â€“ Institutional AI/FTMO Edition
ðŸ“‰ Redis TimeSeries Aggregation | ðŸ” .env.enc Support | âœ… Audit-Log | âœ… Drawdown-WÃ¤chter
âœ… AI-FÃ¤hig (RSI, VWAP, SMA) | âœ… Pandas-Bridge | ðŸ”’ Dezentral konfigurierbar
"""

import os
import sys
import logging
import hashlib
import numpy as np
import pandas as pd
from datetime import datetime, timezone
from pathlib import Path
from typing import Callable
from concurrent.futures import ThreadPoolExecutor

# === ðŸ” Dynamischer Import des verschlÃ¼sselten .env Loaders ===
decrypt_path = Path("/opt/coreflow/utils")
if decrypt_path.exists():
    sys.path.insert(0, str(decrypt_path))
else:
    raise FileNotFoundError(f"âŒ decrypt_env.py nicht gefunden: {decrypt_path}")

from decrypt_env import load_env, find_latest_env_enc

env_path = find_latest_env_enc()
if not env_path:
    raise FileNotFoundError("âŒ Keine gÃ¼ltige .env.enc-Datei gefunden.")
env = load_env(env_path, "/opt/coreflow/infra/vault/encryption.key")

# === Redis-Client vorbereiten ===
from redis.commands.ts.client import TsClient
from redis import Redis

REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6380"))
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD")

redis_raw = Redis(host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD, decode_responses=True)
ts_client = TsClient(redis_raw)

# === ðŸ” FTMO Audit Logging ===
class FTMO_Logger:
    def __init__(self):
        self.logger = logging.getLogger("ftmo_audit")
        self.logger.setLevel(logging.INFO)

        log_path = os.getenv("FTMO_AUDIT_LOG", "/opt/coreflow/logs/ftmo_audit.log")
        os.makedirs(os.path.dirname(log_path), exist_ok=True)

        handler = logging.FileHandler(log_path)
        handler.setFormatter(logging.Formatter(
            '%(asctime)s|%(levelname)s|%(message)s|HASH:%(hash)s'
        ))
        self.logger.addHandler(handler)

    def log(self, message: str):
        log_hash = hashlib.sha256(message.encode()).hexdigest()[:16]
        self.logger.info(message, extra={'hash': log_hash})

# === ðŸ“‰ Drawdown-Monitor (FTMO-KonformitÃ¤t) ===
class RiskEngine:
    def __init__(self, max_drawdown=5.0):
        self.max_dd = max_drawdown
        self.equity_high = 0.0

    def update(self, current_equity: float) -> bool:
        self.equity_high = max(self.equity_high, current_equity)
        drawdown = (self.equity_high - current_equity) / self.equity_high * 100
        return drawdown >= self.max_dd

# === â±ï¸ Redis OHLCV Aggregation mit Pandas ===
def _redis_ohlcv_aggregation(symbol: str, tf: str, from_ts: int, to_ts: int) -> pd.DataFrame:
    logger = logging.getLogger("coreflow.ts_aggregator")
    logger.info(f"ðŸ§  Redis Aggregation: TS.MRANGE {from_ts} â†’ {to_ts} | symbol={symbol.upper()}")

    try:
        res = ts_client.mrange(
            from_ts,
            to_ts,
            filters=[f"symbol={symbol.lower()}"],
            with_labels=True
        )

        if not res:
            raise ValueError("âŒ Keine Zeitreihendaten gefunden.")

        data = []
        for stream in res:
            for ts, val in stream['data']:
                dt = datetime.fromtimestamp(int(ts) / 1000, tz=timezone.utc)
                data.append((dt, float(val)))

        df = pd.DataFrame(data, columns=["datetime", "value"])
        df.set_index("datetime", inplace=True)
        return df

    except Exception as e:
        logger.error(f"Redis aggregation failed: {e}", exc_info=True)
        raise

# === ðŸ§  AI Feature Engineering ===
def add_ai_features(df: pd.DataFrame) -> pd.DataFrame:
    df['vwap'] = (df['value'] * np.arange(1, len(df) + 1)).cumsum() / np.arange(1, len(df) + 1)
    df['sma20'] = df['value'].rolling(20).mean()
    delta = df['value'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    rs = gain.rolling(14).mean() / loss.rolling(14).mean()
    df['rsi'] = 100 - (100 / (1 + rs))
    return df

# === ðŸ“ˆ Aggregierter Datensatz mit AI Features liefern ===
def get_ohlcv(symbol: str, timeframe: str = '1m') -> pd.DataFrame:
    now = int(datetime.now(tz=timezone.utc).timestamp() * 1000)
    from_ts = now - 3_600_000  # letzte 1 Stunde

    df = _redis_ohlcv_aggregation(symbol, timeframe, from_ts, now)
    if df.empty:
        raise ValueError("âŒ Keine Daten zurÃ¼ckgegeben.")
    return add_ai_features(df)

# === ðŸ“¤ Mocked Order-Platzierung (fÃ¼r reale MT5-Integration anpassbar) ===
def place_order(order: str):
    print(f"ðŸ“¤ Order platziert: {order}")

# === ðŸ§  AI/FTMO Strategy Execution Loop ===
def execute_trade(symbol: str, strategy: Callable[[pd.DataFrame], bool]):
    ftmo_log = FTMO_Logger()
    risk = RiskEngine(max_drawdown=5.0)

    while True:
        try:
            df = get_ohlcv(symbol)
            signal = strategy(df)

            current_equity = 100000.0  # In produktiver Version via Broker abrufen

            if signal and not risk.update(current_equity):
                order = f"BUY {symbol} @ {df['value'].iloc[-1]:.5f}"
                ftmo_log.log(order)
                place_order(order)

        except Exception as e:
            ftmo_log.log(f"ERROR: {str(e)}")
            break  # oder: time.sleep(60)

# === ðŸ§ª Beispielstrategie (Mean-Reversion) ===
def mean_reversion_strategy(df: pd.DataFrame) -> bool:
    return df['value'].iloc[-1] < df['sma20'].iloc[-1] * 0.98

# === ðŸš€ MAIN ===
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    execute_trade("EURUSD", mean_reversion_strategy)
